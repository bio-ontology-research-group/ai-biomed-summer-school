{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0f70b2",
   "metadata": {},
   "source": [
    "# mOWL Tutorial\n",
    "\n",
    "This tutorial will teach you how to use machine learning with ontologies. The tutorial captures the different approaches for generating OWL ontology embeddings, and methods to use them. We rely on the mOWL library which intends to implement all embedding methods for Semantic Web (OWL) ontologies.\n",
    "\n",
    "The majority of libraries for processing OWL ontologies are written in Java while most machine learning libraries are written in Python. First, we will need to access Java libraries in Python so that we can process ontologies and perform reasoning. We rely on the JPype library for this purpose which makes Java classes available in Python. We also have to set the memory available to the Java Virtual Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93421ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mowl\n",
    "mowl.init_jvm(\"40g\") # the amount of memory to assign to the JVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f4b04",
   "metadata": {},
   "source": [
    "We can now access classes from the OWLAPI (the main reference implementation for processing Semantic Web ontologies) through their Python interfaces, just as we would in Java. The next code will load an ontology and classify it using the Elk reasoner. We then query for all subclasses of the Human Phenotype Ontology (HPO) class \"Mode of inheritance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b658594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from org.semanticweb.elk.owlapi import ElkReasonerFactory\n",
    "from org.semanticweb.owlapi.apibinding import OWLManager\n",
    "from org.semanticweb.owlapi.model import IRI\n",
    "\n",
    "manager = OWLManager.createOWLOntologyManager()\n",
    "fac = manager.getOWLDataFactory()\n",
    "ont = manager.loadOntologyFromOntologyDocument(IRI.create(\"file:merged-phenomenet.owl\"))\n",
    "print(\"Number of classes: \", ont.getClassesInSignature(True).size())\n",
    "\n",
    "reasoner_factory = ElkReasonerFactory()\n",
    "reasoner = reasoner_factory.createReasoner(ont)\n",
    "\n",
    "for i in reasoner.getSubClasses(fac.getOWLClass(IRI.create(\"http://purl.obolibrary.org/obo/HP_0000005\")), False).getFlattened():\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3300340",
   "metadata": {},
   "source": [
    "mOWL wraps some functionality that is commonly used for generating ontology embeddings in the MOWLReasoner class, which can be used to compute a limited form of the deductive closure of an ontology.\n",
    "\n",
    "# Embedding ontologies\n",
    "\n",
    "mOWL implements several different ontology embeddings. The overall recipe of embedding ontologies is:\n",
    "* generate a Dataset for the ontology\n",
    "* project the OWL ontology suitable for an embedding\n",
    "* apply the embedding model\n",
    "* infer axioms using an inference model\n",
    "* (optional) evaluate the embeddings using an evaluation set\n",
    "\n",
    "## Datasets\n",
    "\n",
    "mOWL operates on OWL axioms, and every dataset consists of a set of OWL axioms (here, also called an ontology). mOWL also provides several datasets for testing purposes, and we will use a small dataset here first, the PPI Yeast Slim Dataset.\n",
    "\n",
    "PPIYeastSlimDataset consists of axioms from the Gene Ontology (GO), in particular the \"yeast slim\" of the GO, a set of yeast proteins, and an association between proteins and GO classes. The GO is natively available in OWL, but the associations are commonly available only as \"annotation\" file from various websites. This dataset makes a particular ontological commitment and represents all proteins as OWL classes. Given a protein $P$ and GO class $G$ that is an annotation of $P$, the following axiom is in the PPIYeastSlimDataset: $P \\sqsubseteq \\exists hasFunction.G$. PPIYeastSlimDataset further adds protein--protein interactions to the ontology; if protein $P_1$ interacts with $P_2$, the axioms $P_1 \\sqsubseteq \\exists interactsWith.P2$ and $P_2 \\sqsubseteq \\exists interactsWith.P_1$ are added.\n",
    "\n",
    "We can print the axioms in the ontology underlying `PPIYeastSlimDataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a867864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mowl.datasets.ppi_yeast import PPIYeastSlimDataset\n",
    "\n",
    "dataset = PPIYeastSlimDataset()\n",
    "for i in dataset.ontology.getAxioms(True):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c620d2",
   "metadata": {},
   "source": [
    "A Dataset may additionally have validation and testing data. Both validation and testing are again sets of axioms (ontologies). For the `PPIYeastSlimDataset`, both validation and testing is done only on interactions. We can investigate the axioms used for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset.testing.getAxioms(True):\n",
    "    print(i)\n",
    "print(dataset.testing.getAxioms(True).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ae52e",
   "metadata": {},
   "source": [
    "## Graph generation\n",
    "\n",
    "projection operation from axioms into graphs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from org.mowl.Projectors import DL2VecProjector\n",
    "projector = DL2VecProjector( True)\n",
    "edges = projector.project(dataset.ontology)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a79676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pylab as plt\n",
    "\n",
    "elist = []\n",
    "count = 5000\n",
    "for i in edges:\n",
    "    if count > 0:\n",
    "        elist.append( (i.src(), i.dst()) )\n",
    "    count -= 1\n",
    "    \n",
    "G=nx.from_edgelist(elist)\n",
    "nx.draw(G, node_size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30b86c",
   "metadata": {},
   "source": [
    "Now that we generated a graph from the OWL axioms, we can embed the graph using any (heterogeneous) graph embedding method. The reason we need a method to embed \"heterogeneous\" graphs is that the projection operations we use consider the relation types, and they should be treated differently in the embedding. Fortunately, there are *many* methods to generate [Knowledge Graph Embeddings](https://persagen.com/files/misc/Wang2017Knowledge.pdf) and mOWL provides access to most of them either by directly implementing them or through the [PyKEEN library](https://github.com/pykeen/pykeen).\n",
    "\n",
    "Let's start by using embeddings based on random walks over the graph followed by Word2Vec. This method applies a repeated random walk starting from each node to generate a \"corpus\", followed by a word embedding that captures co-occurrence relations in this corpus. We have to set some parameters: the number of walks from each node; the length/depth of the random walk; a restart probability; and a file to write these walks to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mowl.walking.deepwalk.model import DeepWalk\n",
    "walker = DeepWalk(\n",
    "\t              100, # number of walks\n",
    "\t\t\t\t  10, # length of each walk\n",
    "\t\t\t\t  0, # probability of restart\n",
    "\t\t\t\t  workers = 8, # number of usable CPUs\n",
    "                  outfile = '/tmp/a.out'\n",
    "\t\t\t\t  )\n",
    "\n",
    "walks = walker.walk(edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2d5da",
   "metadata": {},
   "source": [
    "We can now embed the corpus using a language model like Word2Vec. Word2Vec captures co-occurrence relations within a window. We just use a standard Word2Vec implementation here. Parameters we have to set is the embedding method (Skipgrap or Continuout Bag Of Words), the minimum occurrence count of a word (should be set to `1` as otherwise some embeddings may be missing), the embedding size, the window size (within which co-occurrence is evaluated), and the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecedcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "\n",
    "corpus = LineSentence(\"/tmp/a.out\")\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "       corpus,\n",
    "       sg=1,\n",
    "       min_count=1,\n",
    "       vector_size=3,\n",
    "       window = 10,\n",
    "       epochs = 10,\n",
    "       workers = 16)\n",
    "\n",
    "vectors = w2v_model.wv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae2e40",
   "metadata": {},
   "source": [
    "The result of the embedding is a set of vectors representing each word in the corpus, and therefore one vector for each entity that was included in the graph generated from the ontology axioms. We can visualize these embeddings using a TNSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbe80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = [i for i in w2v_model.wv.key_to_index]\n",
    "tokens = w2v_model[labels]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93f35a",
   "metadata": {},
   "source": [
    "As we can see, the embeddings (somehow) cluster according to their Enzyme Classification. We may then use a similarity function between the embedding vectors to generate \"meaningful\" relations. In mOWL, meaningful relations between OWL entities are expressed in the form of OWL axioms. To obtain axioms from the embeddings, we need an inference method that uses similarity to determine axioms. Here, we rely on cosine similarity between (proteins) $X$ and $Y$ in order to predict axioms of the form $X \\sqsubseteq \\exists interactsWith.Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274adb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d4a5d94",
   "metadata": {},
   "source": [
    "Random walks are a form of embedding of graphs that relies on adjacency. However, other knowledge graph embeddings are more explicit about the kind of graph properties they preserve. For example, [TransE](https://paperswithcode.com/method/transe) generates embeddings $e$ for nodes and edge types such that $e(h) + e(r) \\approx e(t)$ if $r(h,t)$ is an edge in the graph. But there are hundreds of similar embedding methods available, and we rely on the PyKEEN library for accessing these kinds of embeddings. Here is an example of using TransE to generate an embedding of the projected graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8db2d2fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TranslationalOnt' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cuda0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m trans_model \u001b[38;5;241m=\u001b[39m \u001b[43mTranslationalOnt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m     \u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m     \u001b[49m\u001b[43mtrans_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m     \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(cuda0)\n\u001b[1;32m     13\u001b[0m trans_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     14\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m trans_model\u001b[38;5;241m.\u001b[39mget_embeddings()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TranslationalOnt' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "from mowl.embeddings.translational.model import TranslationalOnt\n",
    "import torch\n",
    "cuda0 = torch.device('cuda:0')\n",
    "\n",
    "trans_model = TranslationalOnt(\n",
    "     edges,\n",
    "     trans_method = \"transE\",\n",
    "     embedding_dim = 50,\n",
    "     epochs = 20,\n",
    "     batch_size = 32\n",
    " )\n",
    "\n",
    "trans_model.train()\n",
    "embeddings = trans_model.get_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6f277",
   "metadata": {},
   "source": [
    "## Embeddings without projection\n",
    "\n",
    "So far, we have just reused knowledge graph embedding methods, and first projected ontologies onto graphs. This works great, in particular as there are so many knowledge graph embedding methods available. However, there are some disadvantages; in particular, projecting axioms onto graphs will almost always lose some information. For example, almost no graph projection method will adequately deal with disjointness between classes, or they may not consider axioms of a certain complexity. mOWL implements a number of embedding methods that are based directly on axioms. We can try one of the simplest methods, Onto2Vec, which simply applies a language model to the ontology axioms directly. We first extract the axioms as a \"corpus\" (set of sentences), and then we embed this using Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aba4abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Generating axioms corpus\n",
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 50000 words, keeping 4067 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 100000 words, keeping 5495 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 150000 words, keeping 6434 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 200000 words, keeping 7012 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 250000 words, keeping 7491 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 300000 words, keeping 7852 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 350000 words, keeping 8212 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 400000 words, keeping 8566 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 450000 words, keeping 8835 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 500000 words, keeping 9054 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 550000 words, keeping 9255 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 600000 words, keeping 9454 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 650000 words, keeping 9636 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 700000 words, keeping 9809 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 750000 words, keeping 9955 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 800000 words, keeping 10072 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 850000 words, keeping 10189 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 900000 words, keeping 10324 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 950000 words, keeping 10433 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 1000000 words, keeping 10521 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 1050000 words, keeping 10629 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 1100000 words, keeping 10715 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 1150000 words, keeping 10817 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 1200000 words, keeping 10896 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 1252122 words, keeping 13035 word types\n",
      "INFO:gensim.models.word2vec:collected 14528 word types from a corpus of 1260829 raw words and 251266 sentences\n",
      "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 14528 unique words (100.00% of original 14528, drops 0)', 'datetime': '2022-06-21T12:44:39.845251', 'gensim': '4.2.0', 'python': '3.9.13 (main, Jun 18 2022, 14:46:03) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-39-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 1260829 word corpus (100.00% of original 1260829, drops 0)', 'datetime': '2022-06-21T12:44:39.845768', 'gensim': '4.2.0', 'python': '3.9.13 (main, Jun 18 2022, 14:46:03) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-39-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 14528 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 4 most-common words\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 577414.0195972878 word corpus (45.8%% of prior 1260829)', 'datetime': '2022-06-21T12:44:39.895758', 'gensim': '4.2.0', 'python': '3.9.13 (main, Jun 18 2022, 14:46:03) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-39-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:estimated required memory for 14528 words and 20 dimensions: 9588480 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-06-21T12:44:39.979105', 'gensim': '4.2.0', 'python': '3.9.13 (main, Jun 18 2022, 14:46:03) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-39-generic-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 8 workers on 14528 vocabulary and 20 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-06-21T12:44:39.979430', 'gensim': '4.2.0', 'python': '3.9.13 (main, Jun 18 2022, 14:46:03) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-39-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "INFO:gensim.models.word2vec:EPOCH 0: training on 1260829 raw words (577362 effective words) took 0.9s, 647357 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 1: training on 1260829 raw words (577267 effective words) took 0.9s, 618122 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 2: training on 1260829 raw words (577483 effective words) took 0.8s, 717815 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 3: training on 1260829 raw words (578020 effective words) took 0.9s, 636399 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 4: training on 1260829 raw words (577256 effective words) took 0.9s, 623234 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 5: training on 1260829 raw words (577890 effective words) took 0.8s, 722384 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 6: training on 1260829 raw words (577531 effective words) took 0.9s, 625338 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 7: training on 1260829 raw words (577570 effective words) took 0.9s, 634270 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 8: training on 1260829 raw words (577385 effective words) took 0.8s, 724634 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 9: training on 1260829 raw words (577213 effective words) took 0.9s, 608486 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 10: training on 1260829 raw words (577206 effective words) took 0.9s, 619884 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 11: training on 1260829 raw words (577347 effective words) took 0.8s, 726525 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 12: training on 1260829 raw words (577286 effective words) took 0.9s, 632703 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 13: training on 1260829 raw words (577478 effective words) took 0.9s, 648454 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 14: training on 1260829 raw words (577539 effective words) took 0.8s, 724860 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 15: training on 1260829 raw words (577318 effective words) took 0.9s, 644133 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 16: training on 1260829 raw words (577559 effective words) took 1.0s, 606270 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 17: training on 1260829 raw words (577025 effective words) took 0.8s, 705363 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 18: training on 1260829 raw words (577410 effective words) took 0.9s, 641494 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 19: training on 1260829 raw words (577499 effective words) took 1.0s, 589097 effective words/s\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 25216580 raw words (11548644 effective words) took 17.8s, 650173 effective words/s', 'datetime': '2022-06-21T12:44:57.742109', 'gensim': '4.2.0', 'python': '3.9.13 (main, Jun 18 2022, 14:46:03) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-39-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=14528, vector_size=20, alpha=0.025>', 'datetime': '2022-06-21T12:44:57.742452', 'gensim': '4.2.0', 'python': '3.9.13 (main, Jun 18 2022, 14:46:03) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-39-generic-x86_64-with-glibc2.35', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from mowl.corpus.base import extract_axiom_corpus, extract_annotation_corpus\n",
    "\n",
    "extract_axiom_corpus(dataset.ontology, \"/tmp/corpus\")\n",
    "extract_annotation_corpus(dataset.ontology, \"/tmp/corpus\")\n",
    "\n",
    "sentences = LineSentence(\"/tmp/corpus\")\n",
    "\n",
    "model = Word2Vec(\n",
    "         sentences,\n",
    "         sg = 1,\n",
    "         min_count = 1,\n",
    "         vector_size = 20,\n",
    "         window = 5,\n",
    "         epochs = 20,\n",
    "         workers = 8\n",
    "     )\n",
    "\n",
    "vectors = model.wv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbab454",
   "metadata": {},
   "source": [
    "As before we can now visualize the embeddings generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce1f8913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(10 11)\n",
      "INFO:root:de.tudresden.inf.lat.jcel.owlapi.translator.TranslationException: The translation map is incomplete. Item id was not found: '10'.\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(13 12)\n",
      "INFO:root:de.tudresden.inf.lat.jcel.owlapi.translator.TranslationException: The translation map is incomplete. Item id was not found: '13'.\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(14 12)\n",
      "INFO:root:de.tudresden.inf.lat.jcel.owlapi.translator.TranslationException: The translation map is incomplete. Item id was not found: '14'.\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11032 11033)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubObjectPropert' object has no attribute 'getSubClass'\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11035 11034)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubObjectPropert' object has no attribute 'getSubClass'\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11036 11034)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubObjectPropert' object has no attribute 'getSubClass'\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11028 11028 11028)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubPropertyChain' object has no attribute 'getSubClass'\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11029 11029 11029)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubPropertyChain' object has no attribute 'getSubClass'\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11030 11028 11030)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubPropertyChain' object has no attribute 'getSubClass'\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11032 11032 11032)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubPropertyChain' object has no attribute 'getSubClass'\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11034 11034 11034)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubPropertyChain' object has no attribute 'getSubClass'\n",
      "INFO:root:Reverse translation. Ignoring axiom: SubObjectPropertyOf*(11035 11035 11036)\n",
      "INFO:root:'uk.ac.manchester.cs.owl.owlapi.OWLSubPropertyChain' object has no attribute 'getSubClass'\n",
      "  0%|▏                                                                                                                                                                  | 1/1000 [00:00<05:28,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss: 18.812522888183594 Valid loss: 3.277822732925415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████████▎                                                                                                                                                | 101/1000 [00:28<04:19,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train loss: 14.440105438232422 Valid loss: 8.216601371765137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████████████████▎                                                                                                                                | 201/1000 [01:21<07:24,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: Train loss: 9.77015209197998 Valid loss: 6.098239898681641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████████████████████▍                                                                                                                | 301/1000 [02:16<06:20,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300: Train loss: 5.534924507141113 Valid loss: 3.9293007850646973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████████████████████▌                                                                                                | 401/1000 [03:12<05:53,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400: Train loss: 2.808547258377075 Valid loss: 2.105682611465454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████████████████████████▋                                                                                | 501/1000 [04:11<04:35,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: Train loss: 1.3788771629333496 Valid loss: 1.1004284620285034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 601/1000 [05:15<04:01,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600: Train loss: 0.9211624264717102 Valid loss: 0.8035350441932678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 701/1000 [06:13<02:47,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700: Train loss: 0.7109959721565247 Valid loss: 0.6822091341018677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 801/1000 [07:11<01:48,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800: Train loss: 0.5741439461708069 Valid loss: 0.6165156960487366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 901/1000 [08:09<00:58,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900: Train loss: 0.47862234711647034 Valid loss: 0.5720652937889099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [09:06<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from mowl.embeddings.elembeddings.model import ELEmbeddings\n",
    "import torch\n",
    "\n",
    "cuda0 = torch.device('cuda:0')\n",
    "\n",
    "model = ELEmbeddings(\n",
    "     dataset,\n",
    "     epochs = 1000,\n",
    "     margin = 0.1,\n",
    "     model_filepath = \"model.th\",\n",
    " )\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70185682",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_evaluation_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb24160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
